{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"week8.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Naive Bayes Classification\n","Naive Bayes is a classification algorithm that works based on the Bayes theorem. Although, it's based on bayes theorem, but it can be implemented using different functions. Today, we will build our model using the Categorical Naive Bayes implementation from `sklearn`."],"metadata":{"id":"kStjdAx_KCIn"}},{"cell_type":"markdown","source":["#Libraries for the Implementation\n","We will use several libraries today. We need to import NumPy, Matplot Library and Pandas and sklearn."],"metadata":{"id":"2MFohRXyL-0i"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.naive_bayes import CategoricalNB"],"metadata":{"id":"4I0TFDaq1XHD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The Dataset we will use contains Qualitative/Categorical attributes in it. The \"Golf Data Sample\" is the Dataset that we will use as an example today. We have imported the dataset into a dataframe and split it into two numpy arrays, `X` containing the values of the predictors and `y` containing the label values."],"metadata":{"id":"A7Ok7_5kMd8s"}},{"cell_type":"code","source":["dataset = pd.read_csv('Golf Data Sample.csv')\n","X = dataset.iloc[:, :3].values\n","y = dataset.iloc[:, 3:].values\n","print (X)\n","print (y)"],"metadata":{"id":"qiUjWvK06n-V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648141353963,"user_tz":0,"elapsed":20,"user":{"displayName":"Antony Itki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgllUKtQ8JhgCpPfrevCWnrdA507I4NgH19J3tX=s64","userId":"05566275603956657475"}},"outputId":"662693b8-7a79-45cf-a9f0-efda5313b718"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['Sunny' 'Hot' 'Low']\n"," ['Sunny' 'Hot' 'High']\n"," ['Sunny' 'Hot' 'High']\n"," ['Sunny' 'Mild' 'High']\n"," ['Sunny' 'Mild' 'Low']\n"," ['Overcast' 'Mild' 'High']\n"," ['Overcast' 'Hot' 'High']\n"," ['Overcast' 'Mild' 'Low']\n"," ['Overcast' 'Hot' 'High']\n"," ['Rain' 'Mild' 'High']\n"," ['Rain' 'Mild' 'Low']\n"," ['Rain' 'Hot' 'High']\n"," ['Rain' 'Mild' 'High']\n"," ['Rain' 'Mild' 'High']]\n","[['Play']\n"," ['Dont Play']\n"," ['Dont Play']\n"," ['Dont Play']\n"," ['Play']\n"," ['Play']\n"," ['Play']\n"," ['Play']\n"," ['Play']\n"," ['Dont Play']\n"," ['Dont Play']\n"," ['Play']\n"," ['Play']\n"," ['Play']]\n"]}]},{"cell_type":"markdown","source":["Since, the dataset contains Qualitative/Categorical values we need to encode them into discrete, numerical values. We are using the `LabelEncoder` function for this operation. Notice that we have split the `X`2d array into 3 arrays, this is because the `LabelEncoder` function can only process 1d arrays, so each column in the `X` array in put into a 1d array and then encoded. Afterwards, we aggregated the encoded column values into another 2d numpy array, `X_converted`."],"metadata":{"id":"bjSRf0NMM5qu"}},{"cell_type":"code","source":["\n","le = LabelEncoder()\n","\n","y_converted = le.fit_transform(y)\n","\n","print(y)\n","print(y_converted)\n","\n","x_outlook= X[:,:1]\n","x_outlook=x_outlook.reshape(14)\n","print(x_outlook.shape)\n","print(x_outlook)\n","x_outlook=le.fit_transform(x_outlook)\n","print(x_outlook)\n","\n","x_temperature= X[:,1:2]\n","x_temperature=x_temperature.reshape(14)\n","print(x_temperature.shape)\n","print(x_temperature)\n","x_temperature=le.fit_transform(x_temperature)\n","print(x_temperature)\n","\n","x_humidity= X[:,2:3]\n","x_humidity=x_humidity.reshape(14)\n","print(x_humidity.shape)\n","print(x_humidity)\n","x_humidity=le.fit_transform(x_humidity)\n","print(x_humidity)\n","\n","\n","X_converted=np.array([x_outlook,x_temperature,x_humidity])\n","X_converted=X_converted.reshape(14,3)\n","print(X_converted.shape)\n","print(X_converted)"],"metadata":{"id":"UeauKfLK9sFa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648141353963,"user_tz":0,"elapsed":11,"user":{"displayName":"Antony Itki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgllUKtQ8JhgCpPfrevCWnrdA507I4NgH19J3tX=s64","userId":"05566275603956657475"}},"outputId":"f61ee88f-a57a-4778-8aa5-c24ee047dcb1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['Play']\n"," ['Dont Play']\n"," ['Dont Play']\n"," ['Dont Play']\n"," ['Play']\n"," ['Play']\n"," ['Play']\n"," ['Play']\n"," ['Play']\n"," ['Dont Play']\n"," ['Dont Play']\n"," ['Play']\n"," ['Play']\n"," ['Play']]\n","[1 0 0 0 1 1 1 1 1 0 0 1 1 1]\n","(14,)\n","['Sunny' 'Sunny' 'Sunny' 'Sunny' 'Sunny' 'Overcast' 'Overcast' 'Overcast'\n"," 'Overcast' 'Rain' 'Rain' 'Rain' 'Rain' 'Rain']\n","[2 2 2 2 2 0 0 0 0 1 1 1 1 1]\n","(14,)\n","['Hot' 'Hot' 'Hot' 'Mild' 'Mild' 'Mild' 'Hot' 'Mild' 'Hot' 'Mild' 'Mild'\n"," 'Hot' 'Mild' 'Mild']\n","[0 0 0 1 1 1 0 1 0 1 1 0 1 1]\n","(14,)\n","['Low' 'High' 'High' 'High' 'Low' 'High' 'High' 'Low' 'High' 'High' 'Low'\n"," 'High' 'High' 'High']\n","[1 0 0 0 1 0 0 1 0 0 1 0 0 0]\n","(14, 3)\n","[[2 2 2]\n"," [2 2 0]\n"," [0 0 0]\n"," [1 1 1]\n"," [1 1 0]\n"," [0 0 1]\n"," [1 1 0]\n"," [1 0 1]\n"," [1 0 1]\n"," [1 1 0]\n"," [0 0 1]\n"," [0 0 1]\n"," [0 0 1]\n"," [0 0 0]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}]},{"cell_type":"markdown","source":["In this step, we are are doing a Train-Test split on our dataset. The test set size we are selecting is 45% or, 0.45. "],"metadata":{"id":"hw69NCECOocO"}},{"cell_type":"code","source":["\n","X_train, X_test, y_train, y_test = train_test_split(X_converted, y_converted, test_size = 0.45, random_state=0)\n","print(X_train)\n","print('*****')\n","print(X_test)"],"metadata":{"id":"0ltPF_iA767O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648141354402,"user_tz":0,"elapsed":445,"user":{"displayName":"Antony Itki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgllUKtQ8JhgCpPfrevCWnrdA507I4NgH19J3tX=s64","userId":"05566275603956657475"}},"outputId":"fa9e8bd8-c7d3-47bb-962b-81a3fb0e75ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[2 2 0]\n"," [1 0 1]\n"," [0 0 1]\n"," [1 1 1]\n"," [2 2 2]\n"," [0 0 1]\n"," [0 0 1]]\n","*****\n","[[1 0 1]\n"," [1 1 0]\n"," [1 1 0]\n"," [0 0 1]\n"," [0 0 0]\n"," [0 0 0]\n"," [1 1 0]]\n"]}]},{"cell_type":"markdown","source":["We will now train the model and then, for the 45% test data, we will find the predictive output."],"metadata":{"id":"ZajaQE7iPcDZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2mGxdDJswe3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648141354405,"user_tz":0,"elapsed":43,"user":{"displayName":"Antony Itki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgllUKtQ8JhgCpPfrevCWnrdA507I4NgH19J3tX=s64","userId":"05566275603956657475"}},"outputId":"2e8c0068-cd14-4c79-ca5f-c2cb6d2961bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1 0 0 1 1 1 0]\n"]}],"source":["\n","\n","clf = CategoricalNB()\n","clf.fit(X_train, y_train)\n","\n","y_pred=clf.predict(X_test)\n","print(y_pred)\n","\n"]},{"cell_type":"markdown","source":["We can also check the accuracy by the `accuracy_score`function that compares the predicted and actual values of the label as below:"],"metadata":{"id":"mcD7nIRnP8IV"}},{"cell_type":"code","source":["\n","ac = accuracy_score(y_test,y_pred)\n","print(ac)"],"metadata":{"id":"NOVibjWBGKPH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648141354408,"user_tz":0,"elapsed":40,"user":{"displayName":"Antony Itki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgllUKtQ8JhgCpPfrevCWnrdA507I4NgH19J3tX=s64","userId":"05566275603956657475"}},"outputId":"004ad124-f5d6-4240-cc4b-9efb7e091053"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5714285714285714\n"]}]},{"cell_type":"markdown","source":["We can try predicting the outcome of the new datapoint to see whether, Golf will be \"Play\" or, \"Don't Play\". Here, the new/unseen datapoint is contained in a numpy array."],"metadata":{"id":"9vQFK7R_QUoi"}},{"cell_type":"code","source":["\n","new_row=np.array(['Sunny','Hot','High'])\n","new_row_converted=le.fit_transform(new_row)\n","new_row_converted=new_row_converted.reshape(1,3)\n","print(new_row_converted.shape)\n","y_pred=clf.predict(new_row_converted)\n","print(y_pred)"],"metadata":{"id":"FWAHIwoeHSao","executionInfo":{"status":"ok","timestamp":1648141354410,"user_tz":0,"elapsed":36,"user":{"displayName":"Antony Itki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgllUKtQ8JhgCpPfrevCWnrdA507I4NgH19J3tX=s64","userId":"05566275603956657475"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5c29d86a-a4de-458e-ccda-db9d8952f5a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 3)\n","[0]\n"]}]},{"cell_type":"markdown","source":["#Question:1\n","Using the \"London Train Sample\" Dataset, predict the Class for a new datapoint, where day is \"Saturday\" , Season is \"Spring\", Rain is \"None\", and wind is \"Slight\". You can take necessary help from the code given above."],"metadata":{"id":"LdsyzDGPQ0ez"}},{"cell_type":"code","source":["#Solution:\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","dataset = pd.read_csv('London Train Sample.csv')\n","X = dataset.iloc[:, :4].values\n","y = dataset.iloc[:, 4:].values\n","print (X)\n","print (y)\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","y_converted = le.fit_transform(y)\n","print(y)\n","print(y_converted)\n","x_Day= X[:,:1]\n","x_Day=x_Day.reshape(16)\n","print(x_Day.shape)\n","print(x_Day)\n","x_Day=le.fit_transform(x_Day)\n","print(x_Day)\n","x_Season= X[:,1:2]\n","x_Season=x_Season.reshape(16)\n","print(x_Season.shape)\n","print(x_Season)\n","x_Season=le.fit_transform(x_Season)\n","print(x_Season)\n","x_Wind= X[:,2:3]\n","x_Wind=x_Wind.reshape(16)\n","print(x_Wind.shape)\n","print(x_Wind)\n","x_Wind=le.fit_transform(x_Wind)\n","print(x_Wind)\n","x_Rain= X[:,3:]\n","x_Rain=x_Rain.reshape(16)\n","print(x_Rain.shape)\n","print(x_Rain)\n","x_Rain=le.fit_transform(x_Rain)\n","print(x_Rain)\n","X_converted=np.array([x_Day,x_Season,x_Wind,x_Rain])\n","X_converted=X_converted.reshape(16,4)\n","print(X_converted.shape)\n","print(X_converted)\n","from sklearn.model_selection import train_test_split\n","#X_train, X_test, y_train, y_test = train_test_split(X_converted, y_converted, test_size =\n","X_train, X_test, y_train, y_test = train_test_split(X_converted, y_converted, test_size = 0.45, random_state=0)\n","print(X_train)\n","print(X_test)\n","import numpy as np\n","from sklearn.naive_bayes import CategoricalNB\n","clf = CategoricalNB()\n","clf.fit(X_train, y_train)\n","y_pred=clf.predict(X_test)\n","print(y_pred)\n","from sklearn.metrics import accuracy_score\n","ac = accuracy_score(y_test,y_pred)\n","print(ac)\n","new_row=np.array(['Saturday','Spring','None','Slight'])\n","new_row_converted=le.fit_transform(new_row)\n","new_row_converted=new_row_converted.reshape(1,4)\n","print(new_row_converted.shape)\n","y_pred=clf.predict(new_row_converted)\n","print(y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"oVW8w-x7Kv5P","executionInfo":{"status":"error","timestamp":1648141395947,"user_tz":0,"elapsed":242,"user":{"displayName":"Antony Itki","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgllUKtQ8JhgCpPfrevCWnrdA507I4NgH19J3tX=s64","userId":"05566275603956657475"}},"outputId":"7f4b3277-edcc-4d35-91f9-fcafdb75f135"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['Weekday' 'Spring' 'None' 'None']\n"," ['Weekday' 'Winter' 'None' 'Slight']\n"," ['Weekday' 'Weekday' 'None' 'Slight']\n"," ['Weekday' 'Weekday' 'High' 'Heavy']\n"," ['Saturday' 'Summer' 'Normal' 'None']\n"," ['Weekday' 'Autumn' 'Normal' 'None']\n"," ['Holiday' 'Summer' 'High' 'Slight']\n"," ['Sunday' 'Summer' 'Normal' 'None']\n"," ['Weekday' 'Winter' 'High' 'Heavy']\n"," ['Weekday' 'Summer' 'None' 'Slight']\n"," ['Saturday' 'Spring' 'High' 'Heavy']\n"," ['Weekday' 'Summer' 'High' 'Slight']\n"," ['Saturday' 'Winter' 'Normal' 'None']\n"," ['Weekday' 'Summer' 'High' 'None']\n"," ['Weekday' 'Winter' 'Normal' 'Heavy']\n"," ['Holiday' 'Spring' 'Normal' 'Slight']]\n","[['Ontime']\n"," ['Ontime']\n"," ['Ontime']\n"," ['Late']\n"," ['Ontime']\n"," ['Very Late']\n"," ['Ontime']\n"," ['Ontime']\n"," ['Very Late']\n"," ['Ontime']\n"," ['Cancelled']\n"," ['Ontime']\n"," ['Late']\n"," ['Ontime']\n"," ['Very Late']\n"," ['Ontime']]\n","[['Ontime']\n"," ['Ontime']\n"," ['Ontime']\n"," ['Late']\n"," ['Ontime']\n"," ['Very Late']\n"," ['Ontime']\n"," ['Ontime']\n"," ['Very Late']\n"," ['Ontime']\n"," ['Cancelled']\n"," ['Ontime']\n"," ['Late']\n"," ['Ontime']\n"," ['Very Late']\n"," ['Ontime']]\n","[2 2 2 1 2 3 2 2 3 2 0 2 1 2 3 2]\n","(16,)\n","['Weekday' 'Weekday' 'Weekday' 'Weekday' 'Saturday' 'Weekday' 'Holiday'\n"," 'Sunday' 'Weekday' 'Weekday' 'Saturday' 'Weekday' 'Saturday' 'Weekday'\n"," 'Weekday' 'Holiday']\n","[3 3 3 3 1 3 0 2 3 3 1 3 1 3 3 0]\n","(16,)\n","['Spring' 'Winter' 'Weekday' 'Weekday' 'Summer' 'Autumn' 'Summer' 'Summer'\n"," 'Winter' 'Summer' 'Spring' 'Summer' 'Winter' 'Summer' 'Winter' 'Spring']\n","[1 4 3 3 2 0 2 2 4 2 1 2 4 2 4 1]\n","(16,)\n","['None' 'None' 'None' 'High' 'Normal' 'Normal' 'High' 'Normal' 'High'\n"," 'None' 'High' 'High' 'Normal' 'High' 'Normal' 'Normal']\n","[1 1 1 0 2 2 0 2 0 1 0 0 2 0 2 2]\n","(16,)\n","['None' 'Slight' 'Slight' 'Heavy' 'None' 'None' 'Slight' 'None' 'Heavy'\n"," 'Slight' 'Heavy' 'Slight' 'None' 'None' 'Heavy' 'Slight']\n","[1 2 2 0 1 1 2 1 0 2 0 2 1 1 0 2]\n","(16, 4)\n","[[3 3 3 3]\n"," [1 3 0 2]\n"," [3 3 1 3]\n"," [1 3 3 0]\n"," [1 4 3 3]\n"," [2 0 2 2]\n"," [4 2 1 2]\n"," [4 2 4 1]\n"," [1 1 1 0]\n"," [2 2 0 2]\n"," [0 1 0 0]\n"," [2 0 2 2]\n"," [1 2 2 0]\n"," [1 1 2 1]\n"," [0 2 0 2]\n"," [1 1 0 2]]\n","[[0 1 0 0]\n"," [4 2 4 1]\n"," [1 1 0 2]\n"," [2 0 2 2]\n"," [1 3 3 0]\n"," [3 3 3 3]\n"," [2 0 2 2]\n"," [1 2 2 0]]\n","[[1 3 0 2]\n"," [4 2 1 2]\n"," [1 1 1 0]\n"," [2 2 0 2]\n"," [1 1 2 1]\n"," [1 4 3 3]\n"," [3 3 1 3]\n"," [0 2 0 2]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-382dc93e6c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m             \u001b[0mjll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m         \u001b[0mtotal_ll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjll\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_log_prior_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_ll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 4"]}]}]}